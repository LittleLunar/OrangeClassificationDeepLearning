{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "''' IMPORT ALL THE THINGS '''\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, smart_resize\r\n",
    "from tensorflow.keras.models import Sequential, Model\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "''' DEFINE VARIABLES '''\r\n",
    "\r\n",
    "CWD = os.getcwd().replace('\\\\','/') # get current workspace directory\r\n",
    "IMAGE_DIR = f'{CWD}/images'\r\n",
    "TRAIN_DATASET_DIR = f'{IMAGE_DIR}/train'\r\n",
    "TEST_DATASET_DIR = f'{IMAGE_DIR}/test'\r\n",
    "VAL_DATASET_DIR = f'{IMAGE_DIR}/validation'\r\n",
    "\r\n",
    "CATEGORIES = ['clementine','grapefruit','orange']\r\n",
    "\r\n",
    "IMAGE_RESIZE = (224, 224) # size of image to put in Model\r\n",
    "\r\n",
    "AUGMENT_N_IMAGE = 4 # how many time each image get the augmentation\r\n",
    "\r\n",
    "AUGMENT_SAVE_PREFIX = 'aug'\r\n",
    "\r\n",
    "Save_model = 'Model1'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "''' Create Data Augmentation '''\r\n",
    "def run_augmentation( isRun = 0 ):\r\n",
    "\r\n",
    "    if isRun:\r\n",
    "\r\n",
    "        print('Running Augmentation...\\n')\r\n",
    "\r\n",
    "        datagen = ImageDataGenerator(\r\n",
    "            rotation_range=45,\r\n",
    "            width_shift_range=0.2,\r\n",
    "            height_shift_range=0.2,\r\n",
    "            shear_range=0.2,\r\n",
    "            zoom_range=0.2,\r\n",
    "            horizontal_flip=True,\r\n",
    "            fill_mode='reflect' # optional : nearest, constant(125), reflect, wrap\r\n",
    "        ) \r\n",
    "\r\n",
    "        try:\r\n",
    "            for category in CATEGORIES:\r\n",
    "\r\n",
    "                train_image_in_directory = [] \r\n",
    "\r\n",
    "                train_category_directory = f\"{TRAIN_DATASET_DIR}/{category}\"\r\n",
    "\r\n",
    "                for i, image_name in enumerate(os.listdir(train_category_directory)):\r\n",
    "                    \r\n",
    "                    file_path = f\"{train_category_directory}/{image_name}\"\r\n",
    "                    \r\n",
    "                    if (image_name.find(AUGMENT_SAVE_PREFIX) != -1):  # delete old augmentation\r\n",
    "                        if (os.path.exists(file_path)):\r\n",
    "                            os.remove(file_path)\r\n",
    "\r\n",
    "                    elif (image_name.split('.')[1] in ['png', 'jpg', 'jpeg']):\r\n",
    "\r\n",
    "                        image = load_img(file_path)\r\n",
    "                        image = smart_resize(image, IMAGE_RESIZE)\r\n",
    "                        image = img_to_array(image)\r\n",
    "                        train_image_in_directory.append(image)\r\n",
    "\r\n",
    "                train_image_in_directory = np.array(train_image_in_directory)\r\n",
    "                print(f\"{category} : \", end=\"\")\r\n",
    "                print(train_image_in_directory.shape)\r\n",
    "\r\n",
    "                i = 0\r\n",
    "                \r\n",
    "                # save_to_dir (option) : f'{train_category_directory}', 'augmented'\r\n",
    "                for batch in datagen.flow(train_image_in_directory, batch_size=1, save_to_dir=f'{train_category_directory}', save_prefix=AUGMENT_SAVE_PREFIX, save_format='jpg'):\r\n",
    "                    i += 1\r\n",
    "                    # datagen.flow make infinite loop NEED A MANUAL BREAK!!!\r\n",
    "                    if i >= len(train_image_in_directory) * AUGMENT_N_IMAGE:\r\n",
    "                        break\r\n",
    "\r\n",
    "            print('\\nAugmentation Success!!!')\r\n",
    "\r\n",
    "        except Exception as e:\r\n",
    "\r\n",
    "            print('\\nAugmentation Failed...')\r\n",
    "            print('Exception is\\n',e)\r\n",
    "    \r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "run_augmentation(0)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "''' LOAD DATA into Variables '''\r\n",
    "try:\r\n",
    "    print(\"Loading data...\\n\")\r\n",
    "    \r\n",
    "    print('-----------Train-----------')\r\n",
    "    #Load train data\r\n",
    "\r\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "        TRAIN_DATASET_DIR, # train_data path\r\n",
    "        image_size=IMAGE_RESIZE, # each image resize\r\n",
    "        batch_size=1,\r\n",
    "        label_mode='categorical',\r\n",
    "        color_mode='rgb',\r\n",
    "        shuffle=True\r\n",
    "    )\r\n",
    "\r\n",
    "    print(train_dataset.class_names)  # class check\r\n",
    "    print(train_dataset)\r\n",
    "\r\n",
    "\r\n",
    "    print(\"-----------Validation-----------\")\r\n",
    "    #Load validation data\r\n",
    "    valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "        VAL_DATASET_DIR,  # validation_data path\r\n",
    "        image_size=IMAGE_RESIZE,  # each image resize\r\n",
    "        batch_size=1, \r\n",
    "        label_mode='categorical',\r\n",
    "        color_mode='rgb',\r\n",
    "        shuffle=True\r\n",
    "    )\r\n",
    "\r\n",
    "    print(valid_dataset.class_names)  # class check\r\n",
    "    print(valid_dataset)\r\n",
    "\r\n",
    "    print(\"\\nLoad data Success!!!\")\r\n",
    "    \r\n",
    "except Exception as e:\r\n",
    "\r\n",
    "    print(\"\\nLoad data failed...\")\r\n",
    "    print(\"Exception is\",e)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data...\n",
      "\n",
      "-----------Train-----------\n",
      "Found 1884 files belonging to 3 classes.\n",
      "['clementine', 'grapefruit', 'orange']\n",
      "<BatchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float32, tf.float32)>\n",
      "-----------Validation-----------\n",
      "Found 627 files belonging to 3 classes.\n",
      "['clementine', 'grapefruit', 'orange']\n",
      "<BatchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float32, tf.float32)>\n",
      "\n",
      "Load data Success!!!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "''' Get pre train model '''\r\n",
    "VGG = VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\r\n",
    "VGG.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "''' Training and Display result'''\r\n",
    "BATCH_SIZE = [512, 256, 128, 64, 32, 16, 8, 4]\r\n",
    "\r\n",
    "for i, batch in enumerate(BATCH_SIZE):\r\n",
    "    \r\n",
    "    # create model architecture\r\n",
    "    model = tf.keras.models.Sequential([\r\n",
    "                                    VGG,\r\n",
    "                                    tf.keras.layers.Flatten(),\r\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\r\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\r\n",
    "                                    tf.keras.layers.Dense(3, activation='softmax')\r\n",
    "    ])\r\n",
    "    \r\n",
    "    # compile\r\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "    los = tf.keras.losses.categorical_crossentropy\r\n",
    "    model.compile( optimizer = opt , loss = los , metrics = ['accuracy'] )\r\n",
    "    \r\n",
    "    # Training\r\n",
    "    model.fit(\r\n",
    "        \r\n",
    "        train_dataset,  # both data and label cause we use preprocessing\r\n",
    "        validation_data=valid_dataset,\r\n",
    "        batch_size=batch,\r\n",
    "        epochs=10, ### can be change\r\n",
    "        shuffle=True \r\n",
    "    )\r\n",
    "    \r\n",
    "    # Plot the result\r\n",
    "    fig, axs = plt.subplots(1,2, figsize=(16,5))\r\n",
    "    fig.suptitle(f\"Batch size : {batch}\")\r\n",
    "    axs[0].plot(model.history.history['accuracy'])\r\n",
    "    axs[0].plot(model.history.history['val_accuracy'])\r\n",
    "    axs[0].set_title('Accuracy')\r\n",
    "    axs[0].legend(['train', 'validation'], loc='upper left')\r\n",
    "    axs[0].set(xlabel='epoch', ylabel='accuracy')\r\n",
    "\r\n",
    "    axs[1].plot(model.history.history['loss'])\r\n",
    "    axs[1].plot(model.history.history['val_loss'])\r\n",
    "    axs[1].set_title('Loss')\r\n",
    "    axs[1].legend(['train', 'validation'], loc='upper left')\r\n",
    "    axs[1].set(xlabel='epoch', ylabel='loss')\r\n",
    "    \r\n",
    "    ''' Save the model '''\r\n",
    "    model.save(f'{CWD}/Model/{Save_model}/{batch}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1884/1884 [==============================] - 422s 224ms/step - loss: 8.1202 - accuracy: 0.4931 - val_loss: 1.5548 - val_accuracy: 0.4354\n",
      "Epoch 2/10\n",
      "1884/1884 [==============================] - 420s 223ms/step - loss: 2.7550 - accuracy: 0.6624 - val_loss: 1.0314 - val_accuracy: 0.6204\n",
      "Epoch 3/10\n",
      "1884/1884 [==============================] - 421s 223ms/step - loss: 0.6184 - accuracy: 0.7850 - val_loss: 0.8831 - val_accuracy: 0.6651\n",
      "Epoch 4/10\n",
      "1884/1884 [==============================] - 422s 224ms/step - loss: 0.6116 - accuracy: 0.8148 - val_loss: 0.8253 - val_accuracy: 0.7512\n",
      "Epoch 5/10\n",
      "1884/1884 [==============================] - 420s 223ms/step - loss: 0.5569 - accuracy: 0.8413 - val_loss: 0.9053 - val_accuracy: 0.7049\n",
      "Epoch 6/10\n",
      "1884/1884 [==============================] - 419s 222ms/step - loss: 0.4741 - accuracy: 0.8641 - val_loss: 1.0138 - val_accuracy: 0.7512\n",
      "Epoch 7/10\n",
      "1884/1884 [==============================] - 418s 222ms/step - loss: 0.4849 - accuracy: 0.8785 - val_loss: 1.8298 - val_accuracy: 0.7129\n",
      "Epoch 8/10\n",
      "1884/1884 [==============================] - 419s 222ms/step - loss: 0.6746 - accuracy: 0.8763 - val_loss: 1.8377 - val_accuracy: 0.7225\n",
      "Epoch 9/10\n",
      "1884/1884 [==============================] - 418s 222ms/step - loss: 0.4378 - accuracy: 0.8848 - val_loss: 1.8108 - val_accuracy: 0.7512\n",
      "Epoch 10/10\n",
      "1884/1884 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8715"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33c10b0b0cc55e38f734dcc064280dc0ff34218d69d5679cbbfaef4b64bc80d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}