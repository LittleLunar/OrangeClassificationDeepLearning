{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' IMPORT ALL THE THINGS '''\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, smart_resize\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DEFINE VARIABLES '''\n",
    "\n",
    "CWD = os.getcwd().replace('\\\\','/') # get current workspace directory\n",
    "IMAGE_DIR = f'{CWD}/images'\n",
    "TRAIN_DATASET_DIR = f'{IMAGE_DIR}/train'\n",
    "TEST_DATASET_DIR = f'{IMAGE_DIR}/test'\n",
    "VAL_DATASET_DIR = f'{IMAGE_DIR}/validation'\n",
    "\n",
    "CATEGORIES = ['clementine','grapefruit','orange']\n",
    "\n",
    "IMAGE_RESIZE = (224, 224) # size of image to put in Model\n",
    "\n",
    "AUGMENT_N_IMAGE = 4 # how many time each image get the augmentation\n",
    "\n",
    "AUGMENT_SAVE_PREFIX = 'aug'\n",
    "\n",
    "Save_model = 'Model1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create Data Augmentation '''\n",
    "def run_augmentation( isRun = 0 ):\n",
    "\n",
    "    if isRun:\n",
    "\n",
    "        print('Running Augmentation...\\n')\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='reflect' # optional : nearest, constant(125), reflect, wrap\n",
    "        ) \n",
    "\n",
    "        try:\n",
    "            for category in CATEGORIES:\n",
    "\n",
    "                train_image_in_directory = [] \n",
    "\n",
    "                train_category_directory = f\"{TRAIN_DATASET_DIR}/{category}\"\n",
    "\n",
    "                for i, image_name in enumerate(os.listdir(train_category_directory)):\n",
    "                    \n",
    "                    file_path = f\"{train_category_directory}/{image_name}\"\n",
    "                    \n",
    "                    if (image_name.find(AUGMENT_SAVE_PREFIX) != -1):  # delete old augmentation\n",
    "                        if (os.path.exists(file_path)):\n",
    "                            os.remove(file_path)\n",
    "\n",
    "                    elif (image_name.split('.')[1] in ['png', 'jpg', 'jpeg']):\n",
    "\n",
    "                        image = load_img(file_path)\n",
    "                        image = smart_resize(image, IMAGE_RESIZE)\n",
    "                        image = img_to_array(image)\n",
    "                        train_image_in_directory.append(image)\n",
    "\n",
    "                train_image_in_directory = np.array(train_image_in_directory)\n",
    "                print(f\"{category} : \", end=\"\")\n",
    "                print(train_image_in_directory.shape)\n",
    "\n",
    "                i = 0\n",
    "                \n",
    "                # save_to_dir (option) : f'{train_category_directory}', 'augmented'\n",
    "                for batch in datagen.flow(train_image_in_directory, batch_size=1, save_to_dir=f'{train_category_directory}', save_prefix=AUGMENT_SAVE_PREFIX, save_format='jpg'):\n",
    "                    i += 1\n",
    "                    # datagen.flow make infinite loop NEED A MANUAL BREAK!!!\n",
    "                    if i >= len(train_image_in_directory) * AUGMENT_N_IMAGE:\n",
    "                        break\n",
    "\n",
    "            print('\\nAugmentation Success!!!')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print('\\nAugmentation Failed...')\n",
    "            print('Exception is\\n',e)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_augmentation(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "-----------Train-----------\n",
      "Found 1884 files belonging to 3 classes.\n",
      "['clementine', 'grapefruit', 'orange']\n",
      "<BatchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float32, tf.float32)>\n",
      "-----------Validation-----------\n",
      "Found 627 files belonging to 3 classes.\n",
      "['clementine', 'grapefruit', 'orange']\n",
      "<BatchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float32, tf.float32)>\n",
      "\n",
      "Load data Success!!!\n"
     ]
    }
   ],
   "source": [
    "''' LOAD DATA into Variables '''\n",
    "try:\n",
    "    print(\"Loading data...\\n\")\n",
    "    \n",
    "    print('-----------Train-----------')\n",
    "    #Load train data\n",
    "\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        TRAIN_DATASET_DIR, # train_data path\n",
    "        image_size=IMAGE_RESIZE, # each image resize\n",
    "        batch_size=1,\n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(train_dataset.class_names)  # class check\n",
    "    print(train_dataset)\n",
    "\n",
    "\n",
    "    print(\"-----------Validation-----------\")\n",
    "    #Load validation data\n",
    "    valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        VAL_DATASET_DIR,  # validation_data path\n",
    "        image_size=IMAGE_RESIZE,  # each image resize\n",
    "        batch_size=1, \n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(valid_dataset.class_names)  # class check\n",
    "    print(valid_dataset)\n",
    "\n",
    "    print(\"\\nLoad data Success!!!\")\n",
    "    \n",
    "except Exception as e:\n",
    "\n",
    "    print(\"\\nLoad data failed...\")\n",
    "    print(\"Exception is\",e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get pre train model '''\n",
    "VGG = VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "VGG.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1884/1884 [==============================] - 422s 224ms/step - loss: 8.1202 - accuracy: 0.4931 - val_loss: 1.5548 - val_accuracy: 0.4354\n",
      "Epoch 2/10\n",
      "1884/1884 [==============================] - 420s 223ms/step - loss: 2.7550 - accuracy: 0.6624 - val_loss: 1.0314 - val_accuracy: 0.6204\n",
      "Epoch 3/10\n",
      "1884/1884 [==============================] - 421s 223ms/step - loss: 0.6184 - accuracy: 0.7850 - val_loss: 0.8831 - val_accuracy: 0.6651\n",
      "Epoch 4/10\n",
      "1884/1884 [==============================] - 422s 224ms/step - loss: 0.6116 - accuracy: 0.8148 - val_loss: 0.8253 - val_accuracy: 0.7512\n",
      "Epoch 5/10\n",
      "1884/1884 [==============================] - 420s 223ms/step - loss: 0.5569 - accuracy: 0.8413 - val_loss: 0.9053 - val_accuracy: 0.7049\n",
      "Epoch 6/10\n",
      "1884/1884 [==============================] - 419s 222ms/step - loss: 0.4741 - accuracy: 0.8641 - val_loss: 1.0138 - val_accuracy: 0.7512\n",
      "Epoch 7/10\n",
      "1884/1884 [==============================] - 418s 222ms/step - loss: 0.4849 - accuracy: 0.8785 - val_loss: 1.8298 - val_accuracy: 0.7129\n",
      "Epoch 8/10\n",
      "1884/1884 [==============================] - 419s 222ms/step - loss: 0.6746 - accuracy: 0.8763 - val_loss: 1.8377 - val_accuracy: 0.7225\n",
      "Epoch 9/10\n",
      "1884/1884 [==============================] - 418s 222ms/step - loss: 0.4378 - accuracy: 0.8848 - val_loss: 1.8108 - val_accuracy: 0.7512\n",
      "Epoch 10/10\n",
      "1884/1884 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8715"
     ]
    }
   ],
   "source": [
    "''' Training and Display result'''\n",
    "BATCH_SIZE = [512, 256, 128, 64, 32, 16, 8, 4]\n",
    "\n",
    "for i, batch in enumerate(BATCH_SIZE):\n",
    "    \n",
    "    # create model architecture\n",
    "    model = tf.keras.models.Sequential([\n",
    "                                    VGG,\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    los = tf.keras.losses.categorical_crossentropy\n",
    "    model.compile( optimizer = opt , loss = los , metrics = ['accuracy'] )\n",
    "    \n",
    "    # Training\n",
    "    model.fit(\n",
    "        \n",
    "        train_dataset,  # both data and label cause we use preprocessing\n",
    "        validation_data=valid_dataset,\n",
    "        batch_size=batch,\n",
    "        epochs=10, ### can be change\n",
    "        shuffle=True \n",
    "    )\n",
    "    \n",
    "    # Plot the result\n",
    "    fig, axs = plt.subplots(1,2, figsize=(16,5))\n",
    "    fig.suptitle(f\"Batch size : {batch}\")\n",
    "    axs[0].plot(model.history.history['accuracy'])\n",
    "    axs[0].plot(model.history.history['val_accuracy'])\n",
    "    axs[0].set_title('Accuracy')\n",
    "    axs[0].legend(['train', 'validation'], loc='upper left')\n",
    "    axs[0].set(xlabel='epoch', ylabel='accuracy')\n",
    "\n",
    "    axs[1].plot(model.history.history['loss'])\n",
    "    axs[1].plot(model.history.history['val_loss'])\n",
    "    axs[1].set_title('Loss')\n",
    "    axs[1].legend(['train', 'validation'], loc='upper left')\n",
    "    axs[1].set(xlabel='epoch', ylabel='loss')\n",
    "    \n",
    "    ''' Save the model '''\n",
    "    model.save(f'{CWD}/Model/{Save_model}/{batch}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cda8cc9fa9f0703fd0454ebd9e7babe1c1f48803b29321daa28706de2d716a87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
