{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' IMPORT ALL THE THINGS '''\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, smart_resize\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DEFINE VARIABLES '''\n",
    "\n",
    "CWD = os.getcwd().replace('\\\\','/') # get current workspace directory\n",
    "IMAGE_DIR = f'{CWD}/images'\n",
    "TRAIN_DATASET_DIR = f'{IMAGE_DIR}/train'\n",
    "TEST_DATASET_DIR = f'{IMAGE_DIR}/test'\n",
    "VAL_DATASET_DIR = f'{IMAGE_DIR}/validation'\n",
    "\n",
    "CATEGORIES = ['clementine','grapefruit','orange']\n",
    "\n",
    "IMAGE_RESIZE = (224, 224) # size of image to put in Model\n",
    "\n",
    "AUGMENT_N_IMAGE = 5 # how many time each image get the augmentation\n",
    "\n",
    "AUGMENT_SAVE_PREFIX = 'aug'\n",
    "\n",
    "Detail_model = 'resnet50_fc512_do01_fc256_fc3_aug'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create Data Augmentation '''\n",
    "def run_augmentation( isRun = 0 ):\n",
    "\n",
    "    if isRun:\n",
    "\n",
    "        print('Running Augmentation...\\n')\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='reflect' # optional : nearest, constant(125), reflect, wrap\n",
    "        ) \n",
    "\n",
    "        try:\n",
    "            for category in CATEGORIES:\n",
    "\n",
    "                train_image_in_directory = [] \n",
    "\n",
    "                train_category_directory = f\"{TRAIN_DATASET_DIR}/{category}\"\n",
    "\n",
    "                for i, image_name in enumerate(os.listdir(train_category_directory)):\n",
    "                    \n",
    "                    file_path = f\"{train_category_directory}/{image_name}\"\n",
    "                    \n",
    "                    if (image_name.find(AUGMENT_SAVE_PREFIX) != -1):  # delete old augmentation\n",
    "                        if (os.path.exists(file_path)):\n",
    "                            os.remove(file_path)\n",
    "\n",
    "                    elif (image_name.split('.')[1] in ['png', 'jpg', 'jpeg']):\n",
    "\n",
    "                        image = load_img(file_path)\n",
    "                        image = smart_resize(image, IMAGE_RESIZE)\n",
    "                        image = img_to_array(image)\n",
    "                        train_image_in_directory.append(image)\n",
    "\n",
    "                train_image_in_directory = np.array(train_image_in_directory)\n",
    "                print(f\"{category} : \", end=\"\")\n",
    "                print(train_image_in_directory.shape)\n",
    "\n",
    "                i = 0\n",
    "                \n",
    "                # save_to_dir (option) : f'{train_category_directory}', 'augmented'\n",
    "                for batch in datagen.flow(train_image_in_directory, batch_size=1, save_to_dir=f'{train_category_directory}', save_prefix=AUGMENT_SAVE_PREFIX, save_format='jpg'):\n",
    "                    i += 1\n",
    "                    # datagen.flow make infinite loop NEED A MANUAL BREAK!!!\n",
    "                    if i >= len(train_image_in_directory) * AUGMENT_N_IMAGE:\n",
    "                        break\n",
    "\n",
    "            print('\\nAugmentation Success!!!')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print('\\nAugmentation Failed...')\n",
    "            print('Exception is\\n',e)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Augmentation...\n",
      "\n",
      "clementine : (485, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "run_augmentation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' LOAD DATA into Variables '''\n",
    "try:\n",
    "    print(\"Loading data...\\n\")\n",
    "    \n",
    "    print('-----------Train-----------')\n",
    "    #Load train data\n",
    "\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        TRAIN_DATASET_DIR, # train_data path\n",
    "        image_size=IMAGE_RESIZE, # each image resize\n",
    "        batch_size=1,\n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(train_dataset.class_names)  # class check\n",
    "    print(train_dataset)\n",
    "\n",
    "\n",
    "    print(\"-----------Validation-----------\")\n",
    "    #Load validation data\n",
    "    valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        VAL_DATASET_DIR,  # validation_data path\n",
    "        image_size=IMAGE_RESIZE,  # each image resize\n",
    "        batch_size=1, \n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(valid_dataset.class_names)  # class check\n",
    "    print(valid_dataset)\n",
    "\n",
    "    print(\"\\nLoad data Success!!!\")\n",
    "    \n",
    "except Exception as e:\n",
    "\n",
    "    print(\"\\nLoad data failed...\")\n",
    "    print(\"Exception is\",e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get pre train model '''\n",
    "resnet = ResNet50(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Training and Display result'''\n",
    "\n",
    "# create model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "                                resnet,\n",
    "                                tf.keras.layers.Flatten(),\n",
    "                                tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                tf.keras.layers.Dropout(0.1),\n",
    "                                tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "los = tf.keras.losses.categorical_crossentropy\n",
    "model.compile( optimizer = opt , loss = los , metrics = ['accuracy'] )\n",
    "\n",
    "# Training\n",
    "model.fit(\n",
    "    \n",
    "    train_dataset,  # both data and label cause we use preprocessing\n",
    "    validation_data=valid_dataset,\n",
    "    batch_size=256,\n",
    "    epochs=10, ### can be change\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "# Plot the result\n",
    "fig, axs = plt.subplots(1,2, figsize=(16,5))\n",
    "fig.suptitle(f\"{Detail_model}\")\n",
    "axs[0].plot(model.history.history['accuracy'])\n",
    "axs[0].plot(model.history.history['val_accuracy'])\n",
    "axs[0].set_title('Accuracy')\n",
    "axs[0].legend(['train', 'validation'], loc='upper left')\n",
    "axs[0].set(xlabel='epoch', ylabel='accuracy')\n",
    "\n",
    "axs[1].plot(model.history.history['loss'])\n",
    "axs[1].plot(model.history.history['val_loss'])\n",
    "axs[1].set_title('Loss')\n",
    "axs[1].legend(['train', 'validation'], loc='upper left')\n",
    "axs[1].set(xlabel='epoch', ylabel='loss')\n",
    "\n",
    "''' Save the model '''\n",
    "model.save(f'{CWD}/Model/{Detail_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        TEST_DATASET_DIR,  # test_dataset path\n",
    "        image_size=IMAGE_RESIZE,  # each image resize\n",
    "        batch_size=1, \n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(test_dataset.class_names)  # class check\n",
    "print(test_dataset)\n",
    "\n",
    "print(\"\\nLoad data Success!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = f'{CWD}/images/validation/'\n",
    "# for j in os.listdir(dir_path):\n",
    "#     for i in os.listdir(dir_path + '/' + j):\n",
    "#         img = tf.keras.preprocessing.image.load_img(dir_path + '/' +j+'/'+i, target_size=(224,224))\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "\n",
    "#         X= tf.keras.preprocessing.image.img_to_array(img)\n",
    "#         X= np.expand_dims(X,axis=0)\n",
    "#         image = np.vstack([X])\n",
    "#         val = model.predict(image)\n",
    "#         '''print(val)\n",
    "#         print(val[0][0])\n",
    "#         print(val[0][1])\n",
    "#         print(val[0][2])\n",
    "#         print(np.argmax(val)) '''\n",
    "\n",
    "#         if val[0][0] > val[0][1] and val[0][0] > val[0][2] :\n",
    "#             print('this is Clementine : '+i)\n",
    "#             if j == 'clementine':\n",
    "#                 print('Correct')\n",
    "#             else:\n",
    "#                 print('incorrect')\n",
    "            \n",
    "\n",
    "\n",
    "#         elif val[0][1] > val[0][0] and val[0][1] > val[0][2] :\n",
    "#             print('this is Grapefruit : '+i)\n",
    "#             if j == 'grapefruit':\n",
    "#                 print('Correct')\n",
    "#             else:\n",
    "#                 print('incorrect')\n",
    "           \n",
    "\n",
    "#         elif val[0][2] > val[0][0] and val[0][2] > val[0][1] :\n",
    "#             print('this is Orange : '+i)\n",
    "#             if j == 'orange':\n",
    "#                 print('Correct')\n",
    "#             else:\n",
    "#                 print('incorrect')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = load_model(f'{CWD}/Model/{Detail_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(f'{CWD}/images/test/clementine/1000.jpg', target_size=(224,224))\n",
    "print(img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "X= tf.keras.preprocessing.image.img_to_array(img)\n",
    "X= np.expand_dims(X,axis=0)\n",
    "image = np.vstack([X])\n",
    "val = predict_model.predict(image)\n",
    "print(\"Val : \",end=\"\")\n",
    "print(type(val[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cda8cc9fa9f0703fd0454ebd9e7babe1c1f48803b29321daa28706de2d716a87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
